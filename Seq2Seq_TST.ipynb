{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1uyqQg2e8wnA-BScZ_EzQEYQQY5MZa5oN",
      "authorship_tag": "ABX9TyM6xlelYSPwC27bKckYNoJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taravatp/Text_Style_Transfer/blob/main/Seq2Seq_TST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "ycqD2c6LBg3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU hazm"
      ],
      "metadata": {
        "id": "dxA39nYJcVpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "322dff96-ffd4-410b-e9d5-247622c65696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.7/316.7 KB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 KB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "import hazm\n",
        "from hazm import word_tokenize\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "K93qixoyckKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-p0CihSsdal",
        "outputId": "c8932e20-af99-4172-cbfb-6acf7ba3bb1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n",
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "rrLpDovknjgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hazm\n",
        "import re\n",
        "\n",
        "DATASET_PATH = '/content/drive/MyDrive/text_style_transfer/dataset.xlsx'\n",
        "dataset = pd.read_excel(DATASET_PATH)\n",
        "normalizer = hazm.Normalizer()\n",
        "\n",
        "def cleaning(text):\n",
        "  text = text.strip()\n",
        "  text = normalizer.normalize(text) #normalizing\n",
        "  text = re.sub(r\"([.!?])\", r\" \\1\", text) # inserting a space between words and punctuations\n",
        "  text = re.sub(\"\\s+\", \" \", text) #removing redundant white spaces\n",
        "  return text\n",
        "\n",
        "def truncate(sentence,max_len=20):\n",
        "  if len(word_tokenize(sentence)) < max_len:\n",
        "    return sentence\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "dataset['formalForm'] = dataset['formalForm'].apply(cleaning)\n",
        "dataset['formalForm'] = dataset['formalForm'].apply(truncate)\n",
        "\n",
        "dataset['inFormalForm'] = dataset['inFormalForm'].apply(cleaning)\n",
        "dataset['inFormalForm'] = dataset['inFormalForm'].apply(truncate)\n",
        "\n",
        "dataset = dataset.dropna()\n",
        "dataset = dataset.reset_index()"
      ],
      "metadata": {
        "id": "10O2FSgRdtSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the cleaned data\n",
        "writePath = '/content/drive/MyDrive/text_style_transfer/CleanedDataset_v2.csv'\n",
        "dataset.to_csv(writePath, encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "z6KnnVinnLmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating language style objects"
      ],
      "metadata": {
        "id": "WhCUjjjRpv5S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV6VSlNmX3o6"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "DATASET_PATH = '/content/drive/MyDrive/text_style_transfer/CleanedDataset_v2.csv'\n",
        "dataset = pd.read_csv(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LangStyle:\n",
        "  def __init__(self):\n",
        "    self.word2index = {}\n",
        "    self.index2word = {}\n",
        "    self.word2count = {0: \"SOS\", 1: \"EOS\"}\n",
        "    self.n_words = 2\n",
        "\n",
        "  def add_setence_to_lang(self,sentence):\n",
        "    for token in word_tokenize(sentence):\n",
        "      if token not in self.word2index:\n",
        "        self.word2index[token] = self.n_words\n",
        "        self.word2count[token] = 1\n",
        "        self.index2word[self.n_words] = token\n",
        "        self.n_words +=1\n",
        "      else:\n",
        "        self.word2count[token] += 1"
      ],
      "metadata": {
        "id": "ApIaH5yebuMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formalStyle = LangStyle()\n",
        "informalStyle = LangStyle()\n",
        "\n",
        "for index, row in dataset.iterrows():\n",
        "  formalStyle.add_setence_to_lang(row['formalForm'])\n",
        "  informalStyle.add_setence_to_lang(row['inFormalForm'])"
      ],
      "metadata": {
        "id": "_qQ1wQxMpqA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('number of words in formal style:',formalStyle.n_words)\n",
        "print('number of words in informal style:',informalStyle.n_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IKC1a0ZrVmX",
        "outputId": "2d9ffe1b-a8e0-40f2-d61e-be1576a02241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of words in formal style: 28111\n",
            "number of words in informal style: 39847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seq2seq Model"
      ],
      "metadata": {
        "id": "IG8bH1cmrzWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "\n",
        "        # Input size is the size of the dictionary\n",
        "        # hidden size is the size of each embedding vector\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size,5)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(5, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "c-HvRg9-ryMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p, max_length):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size,5)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "\n",
        "        embedded = self.embedding(input).view(1, 1, -1) #????\n",
        "        embedded = self.dropout(embedded) #torch.Size([1, 1, 256])\n",
        "\n",
        "        attention_input = torch.cat((embedded[0], hidden[0]), 1) #[1,512]\n",
        "        attention_output = self.attn(attention_input) #[1,20]\n",
        "        attn_weights = F.softmax(attention_output, dim=1) #[1,20]\n",
        "        mat1 = attn_weights.unsqueeze(0)\n",
        "        mat2 = encoder_outputs\n",
        "        attn_applied = torch.bmm(mat1,mat2) # [1,1,256]\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1) #[1,512]\n",
        "        output = self.attn_combine(output).unsqueeze(0) #[1,1,256]\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output[0])\n",
        "        output = F.log_softmax(output, dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(5, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "0DYKmVUj3jl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating DataLoaders"
      ],
      "metadata": {
        "id": "s77ojVlfsQM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pandas as pd\n",
        "\n",
        "class TSTData(Dataset):\n",
        "  def __init__(self,dataset_path,informalStyle,formalStyle,flag):\n",
        "    super(TSTData,self).__init__()\n",
        "    self.dataset = pd.read_csv(dataset_path)\n",
        "    if flag == 'train':\n",
        "      num_samples_train = int(len(self.dataset) * 0.9)\n",
        "      self.dataset = self.dataset.iloc[:num_samples_train]\n",
        "    else:\n",
        "      num_samples_train = int(len(self.dataset) * 0.9)\n",
        "      self.dataset = self.dataset[num_samples_train:]\n",
        "\n",
        "    self.informalStyle = informalStyle\n",
        "    self.formalStyle = formalStyle\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def sentence_to_tensor(self,sentence,LangStyle):\n",
        "    vector = [LangStyle.word2index[word] for word in word_tokenize(sentence)]\n",
        "    vector.append(EOS_token)\n",
        "    vector = torch.tensor(vector, dtype=torch.long)\n",
        "    return vector\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "\n",
        "    data = self.dataset.iloc[index]\n",
        "    informal_sentence = data['inFormalForm']\n",
        "    formal_sentence = data['formalForm']\n",
        "\n",
        "    informal_tensor = self.sentence_to_tensor(informal_sentence,self.informalStyle)\n",
        "    # informal_tensor = informal_tensor.view(-1,1)\n",
        "    formal_tensor = self.sentence_to_tensor(formal_sentence,self.formalStyle)\n",
        "    # formal_tensor = formal_tensor.view(-1,1)\n",
        "\n",
        "    return (informal_tensor,formal_tensor)"
      ],
      "metadata": {
        "id": "M8FYu5sttAYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "TSh_j7k66u07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = '/content/drive/MyDrive/text_style_transfer/CleanedDataset_v2.csv'\n",
        "HIDDEN_SIZE = 64\n",
        "NUM_EPOCHS = 50\n",
        "LEARNING_RATE = 0.01\n",
        "BATCH_SIZE = 1\n",
        "MAX_LEN = 20\n",
        "TEACHER_FORCE = 1"
      ],
      "metadata": {
        "id": "-23HJUYhzk1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TSTData(DATASET_PATH,informalStyle,formalStyle,'train')\n",
        "test_data = TSTData(DATASET_PATH,informalStyle,formalStyle,'test')\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE)\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
        "\n",
        "encoder = EncoderRNN(informalStyle.n_words, HIDDEN_SIZE).to(device)\n",
        "decoder = DecoderRNN(HIDDEN_SIZE, formalStyle.n_words, 0.1, MAX_LEN).to(device)\n",
        "\n",
        "encoder_optimizer = torch.optim.SGD(encoder.parameters(),lr=LEARNING_RATE)\n",
        "decoder_optimizer = torch.optim.SGD(decoder.parameters(),lr=LEARNING_RATE)\n",
        "criterion = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "fSfPuZgi9jgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "312_6CbhXnLr",
        "outputId": "a8823c0c-3975-4da5-b82c-76783ba3f0b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EncoderRNN(\n",
            "  (embedding): Embedding(39847, 64)\n",
            "  (gru): GRU(64, 64, num_layers=5)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OniVVpDcX71O",
        "outputId": "8e242a1f-4e24-477c-c5ce-a070168fed08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecoderRNN(\n",
            "  (embedding): Embedding(28111, 64)\n",
            "  (attn): Linear(in_features=128, out_features=20, bias=True)\n",
            "  (attn_combine): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (gru): GRU(64, 64, num_layers=5)\n",
            "  (out): Linear(in_features=64, out_features=28111, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "  loss = 0\n",
        "  print('**********************************************************')\n",
        "  losses = []\n",
        "  for iter,batch in enumerate(test_dataloader):\n",
        "    loss = 0\n",
        "    informal_sentence = batch[0].to(device) #[batch_size,num_tokens,1]\n",
        "    formal_sentence  = batch[1].to(device)  #[batch_size,num_tokens,1]\n",
        "\n",
        "\n",
        "    input_length = informal_sentence.shape[1]\n",
        "    target_length = formal_sentence.shape[1]\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    encoder_hidden = encoder.initHidden().to(device) #[1,1,256]\n",
        "    encoder_outputs = torch.zeros(BATCH_SIZE,MAX_LEN, encoder.hidden_size).to(device) #[batch_size,max_len_tokens,hidden_size]\n",
        "\n",
        "    for index in range(input_length):\n",
        "\n",
        "      word = informal_sentence[:,index]\n",
        "      encoder_output, encoder_hidden = encoder(word,encoder_hidden) # encoder_output: [1,1,256] - encdoder_hidden: [1,1,256]\n",
        "      encoder_outputs[:,index,:] = encoder_output\n",
        "\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]]).to(device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    if TEACHER_FORCE > random.random():\n",
        "      for index in range(target_length):\n",
        "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "        loss += criterion(decoder_output, formal_sentence[:,index])\n",
        "        decoder_input = formal_sentence[:,index]\n",
        "    else:\n",
        "      for index in range(target_length):\n",
        "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "        topv, topi = decoder_output.topk(1)\n",
        "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "        loss += criterion(decoder_output, formal_sentence[:,index])\n",
        "\n",
        "        if decoder_input.item() == EOS_token:\n",
        "          break\n",
        "\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    torch.save(encoder.state_dict(), f\"encoder{epoch}.pth\")\n",
        "    torch.save(decoder.state_dict(), f\"decoder{epoch}.pth\")\n",
        "  print(f'end of epoch {epoch} and loss is {sum(losses)/len(test_dataloader)}')"
      ],
      "metadata": {
        "id": "T7ORLFdiwmqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/text_style_transfer"
      ],
      "metadata": {
        "id": "ps2Vw9JPVOok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "aochMavHgaFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  bluescore = 0\n",
        "  for iter,batch in enumerate(test_dataloader):\n",
        "\n",
        "    informal_sentence = batch[0].to(device)\n",
        "    input_length = informal_sentence.shape[1]\n",
        "    encoder_hidden = encoder.initHidden().to(device) #[1,1,256]\n",
        "    encoder_outputs = torch.zeros(BATCH_SIZE,MAX_LEN, encoder.hidden_size).to(device)\n",
        "\n",
        "    for index in range(input_length):\n",
        "      word = informal_sentence[:,index]\n",
        "      encoder_output, encoder_hidden = encoder(word,encoder_hidden) # encoder_output: [1,1,256] - encdoder_hidden: [1,1,256]\n",
        "      encoder_outputs[:,index,:] = encoder_output\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]]).to(device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    decoded_words = []\n",
        "    for index in range(MAX_LEN):\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "      topv, topi = decoder_output.data.topk(1)\n",
        "      if topi.item() == EOS_token:\n",
        "        decoded_words.append('<EOS>')\n",
        "        break\n",
        "      else:\n",
        "        decoded_words.append(formalStyle.index2word[topi.item()])\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "    bluescore += bleu_score(target_sentence,decoded_words)\n",
        "  print(decoded_words)"
      ],
      "metadata": {
        "id": "kCjVbtr2gbUF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}